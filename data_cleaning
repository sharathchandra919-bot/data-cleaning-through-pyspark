from pyspark.sql import (
    SparkSession,
    types,
    functions as F,
)

spark = (
    SparkSession
    .builder
    .appName('cleaning_orders_dataset_with_pyspark')
    .getOrCreate()
)
orders_data = spark.read.parquet('orders_data.parquet')
orders_data = orders_data.withColumn("time_of_day",
                                     F.when((F.hour('order_date') >= 0) & (F.hour('order_date') <= 5), 'night')
                                    .when((F.hour('order_date') >= 6) & (F.hour('order_date') <= 11), 'morning')
                                    .when((F.hour('order_date') >= 12) & (F.hour('order_date') <= 17), 'afternoon')
                                    .when((F.hour('order_date') >= 18) & (F.hour('order_date') <= 23), 'evening')
                                    .otherwise(None)
                                    ).filter(F.col('time_of_day') != 'night'
                                    ).withColumn("order_date",
                                                 F.col('order_date').cast(types.DateType())
                                    )
               
orders_data = orders_data.withColumn('product',
                                     F.lower('product')
                                    ).withColumn('category',
                                                F.lower('category')
                                                ).filter(~F.col('product').contains('tv')
                                                        )

orders_data = orders_data.withColumn('address_split',
                                    F.split('purchase_address'," ")
                                    ).withColumn('purchase_state',
                                                 F.col('address_split').getItem(F.size('address_split') - 2)
                                                ).drop('address_split')

n_states = orders_data.select('purchase_state').distinct().count()

orders_data.write.parquet("orders_data_clean.parquet",mode='overwrite')
